{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to database\n",
    "\n",
    "Creating connection to Microsoft SQL Server and two databases with positive and negative sets. We should use generators for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(constring, query):\n",
    "    cnxn = pyodbc.connect(constring)\n",
    "    cursor = cnxn.cursor()\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    y, t = [], []\n",
    "    for row in cursor:\n",
    "        r_text = row.ttext\n",
    "        r_type = row.ttype\n",
    "        y.append(r_text)\n",
    "        t.append(r_type)\n",
    "        \n",
    "        if len(y) == batch_size:\n",
    "            npx = np.array(y)\n",
    "            npy = np.array(t)\n",
    "            yield npx, npy\n",
    "            y, t = [], []\n",
    "    pyodbc.Connection.close(cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "We should encode words as their indexes (computed by overall frequency in the dataset).\n",
    "Using russian http://www.ruscorpora.ru/en/\n",
    "#### Step 1. Clear dataset. \n",
    "#### Step 2. Select meaningful words.\n",
    "#### Step 3. Calculate frequency of each word\n",
    "#### Step 4. Replace words by indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "hash_map = {}\n",
    "max_features = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Clear dataset. \n",
    "Select words one by one. Symbols are meaningful because of smiles and emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(file_text):\n",
    "    if file_text is not None:\n",
    "        #firstly let's apply nltk tokenization\n",
    "        tokens = nltk.word_tokenize(file_text)\n",
    "\n",
    "        #let's delete punctuation symbols\n",
    "        stop_words = ([',','\\\\','/','*','','-','http',';',':','@'])\n",
    "        tokens = [i for i in tokens if ( i not in stop_words )]\n",
    "\n",
    "        #deleting stop_words\n",
    "        #stop_words = stopwords.words('russian')\n",
    "        #stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'в', '—', 'к', 'на', 'http'])\n",
    "       \n",
    "       # tokens = [i for i in tokens if ( i not in stop_words )]\n",
    "\n",
    "        #cleaning words\n",
    "        #tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
    "\n",
    "        return tokens\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a HashMap by using a Python dictionary to store the word frequencies of a book.\n",
    "A dictionary is an associative array (also known as hashes).\n",
    "Any key of the dictionary is associated, or mapped, to a value.\n",
    "The values of a dictionary can be any Python data type, so dictionaries are unordered key-value-pairs.\n",
    "\n",
    "By creating the dictionary, we will store the words as the keys and the value will represent the count. By doing this, we can retrieve any word without having to recount every single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def map_words(tokens):\n",
    "    \n",
    "    if tokens is not None:\n",
    "        for element in tokens:\n",
    "            # Remove Punctuation\n",
    "            word = element.replace(\",\",\"\")\n",
    "            word = word.replace(\".\",\"\")\n",
    "            word = word.lower()\n",
    "            # Word Exist?\n",
    "            if word in hash_map:\n",
    "                hash_map[word] = hash_map[word] + 1\n",
    "            else:\n",
    "                hash_map[word] = 1\n",
    "\n",
    "        return hash_map\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnstr_positive = 'Trusted_Connection=yes;DRIVER={SQL Server};SERVER=DESKTOP-1RHDOBR\\GORDASQL;DATABASE=positive;UID=pyuser;PWD=pypypy'\n",
    "\n",
    "cnstr_negative = 'Trusted_Connection=yes;DRIVER={SQL Server};SERVER=DESKTOP-1RHDOBR\\GORDASQL;DATABASE=negative;UID=pyuser;PWD=pypypy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_frequency():\n",
    "    hash_map.clear()\n",
    "    \n",
    "    query_positive = \"SELECT top 10000 [ttext], [ttype] FROM [dbo].[sortpos]\"\n",
    "    pdg = data_generator(cnstr_positive, query_positive)\n",
    "    \n",
    "    query_negative = \"SELECT top 10000 [ttext], [ttype] FROM [dbo].[sortneg]\"\n",
    "    ndg = data_generator(cnstr_negative, query_negative)\n",
    "    \n",
    "    for current_positive_set in pdg:\n",
    "        for sentence in current_positive_set[0]:\n",
    "            words = tokenize(sentence)\n",
    "            map = map_words(words)\n",
    "            \n",
    "    for current_negative_set in ndg:\n",
    "        for sentence in current_negative_set[0]:\n",
    "            words = tokenize(sentence)\n",
    "            map = map_words(words)\n",
    "    \n",
    "    min_frequency = 2#max(map.values()) - max_features if max(map.values()) > max_features else 2\n",
    "    map = {key: value for key, value in map.items() if value > min_frequency}\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map = fill_frequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: [привет] Frequency: 129\n",
      "Word: [,] Frequency: 0\n",
      "Word: [дела] Frequency: 60\n",
      "Word: [)] Frequency: 17125\n",
      "Word: [(] Frequency: 18035\n"
     ]
    }
   ],
   "source": [
    "word_list = ['привет',',','дела',')','(']\n",
    "\n",
    "for word in word_list:\n",
    "    print('Word: [' + word + '] Frequency: ' + str(map.get(word,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "maxlen = 32  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_generator():\n",
    "    max_frequency = max(map.values())\n",
    "    \n",
    "    #train_cnt = 500\n",
    "    #cnxn = pyodbc.connect(cnstr_positive)\n",
    "    #query = \"SELECT count(*) as cnt FROM [dbo].[mixedmessages]\"\n",
    "    #cursor = cnxn.cursor()\n",
    "    #cursor.execute(query)\n",
    "    #for row in cursor:\n",
    "    #    train_cnt = row.cnt/2\n",
    "    #pyodbc.Connection.close(cnxn)\n",
    "    \n",
    "    x_train, y_train = ([] for i in range(2))\n",
    "    \n",
    "    query = \"SELECT top 100 [ttext], [ttype] FROM [dbo].[train]\"\n",
    "    while 1:\n",
    "        mdg = data_generator(cnstr_positive, query)\n",
    "\n",
    "        for current_set in mdg:\n",
    "            for sentence in current_set[0]:\n",
    "                words = tokenize(sentence)\n",
    "                w = []\n",
    "                #print(words)\n",
    "                for word in words:\n",
    "                    #print(word, map.get(word,0))\n",
    "                    w.append(max_frequency-map.get(word,0))\n",
    "                x_train.append(w)\n",
    "\n",
    "            for value in current_set[1]:\n",
    "                y_train.append(value)\n",
    "\n",
    "            if len(x_train) == batch_size:\n",
    "                x_train = np.array(x_train)\n",
    "                #y_train = np.array(y_train)\n",
    "                x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "                x_train = x_train.tolist()\n",
    "                yield x_train, y_train  \n",
    "                        \n",
    "    #print(x_train)\n",
    "    #return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dg = train_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   16674,\n",
       "   17970,\n",
       "   17837,\n",
       "   18027,\n",
       "   0,\n",
       "   18035],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   12933,\n",
       "   18010,\n",
       "   15130,\n",
       "   17697,\n",
       "   17588,\n",
       "   17925,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   17917,\n",
       "   18035,\n",
       "   17862,\n",
       "   18024,\n",
       "   17937,\n",
       "   12873,\n",
       "   18028,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   17908,\n",
       "   18035,\n",
       "   18035,\n",
       "   12933,\n",
       "   18035,\n",
       "   18029,\n",
       "   17079,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   16957,\n",
       "   12873,\n",
       "   18016,\n",
       "   18035,\n",
       "   18035,\n",
       "   12229],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17952,\n",
       "   12751,\n",
       "   11692,\n",
       "   17427,\n",
       "   18012,\n",
       "   17522,\n",
       "   17797,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   18030,\n",
       "   18035,\n",
       "   18035,\n",
       "   16674,\n",
       "   16433,\n",
       "   12933,\n",
       "   18011,\n",
       "   17339,\n",
       "   12873,\n",
       "   18021,\n",
       "   17404,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17617,\n",
       "   18035,\n",
       "   16816,\n",
       "   17965,\n",
       "   12933,\n",
       "   17973,\n",
       "   17734,\n",
       "   17582,\n",
       "   18035,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   16957,\n",
       "   12751,\n",
       "   16089,\n",
       "   17366,\n",
       "   11692,\n",
       "   17997,\n",
       "   18035,\n",
       "   11692,\n",
       "   18022,\n",
       "   16410,\n",
       "   16433,\n",
       "   17924],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18026,\n",
       "   18010,\n",
       "   18035,\n",
       "   18035,\n",
       "   17996,\n",
       "   17863,\n",
       "   16089,\n",
       "   17040,\n",
       "   18035,\n",
       "   18027,\n",
       "   18035,\n",
       "   18035,\n",
       "   18028,\n",
       "   14517,\n",
       "   16226,\n",
       "   16089,\n",
       "   14517,\n",
       "   18035,\n",
       "   910,\n",
       "   910,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   17983,\n",
       "   14407,\n",
       "   14407,\n",
       "   12873,\n",
       "   18035,\n",
       "   17985],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17728,\n",
       "   17966,\n",
       "   11692,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   17889,\n",
       "   18027,\n",
       "   18015,\n",
       "   16433,\n",
       "   17889,\n",
       "   18027,\n",
       "   18035,\n",
       "   12229,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   15185,\n",
       "   12751,\n",
       "   17168,\n",
       "   17648,\n",
       "   11692,\n",
       "   17981,\n",
       "   14517,\n",
       "   17995,\n",
       "   18035,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15185,\n",
       "   17270,\n",
       "   18035,\n",
       "   17646,\n",
       "   17929,\n",
       "   18024,\n",
       "   18035,\n",
       "   18023],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   16089,\n",
       "   16433,\n",
       "   18002,\n",
       "   0,\n",
       "   0,\n",
       "   15185,\n",
       "   17675,\n",
       "   17040,\n",
       "   17522,\n",
       "   18031,\n",
       "   18005,\n",
       "   14407,\n",
       "   17697,\n",
       "   17810,\n",
       "   14517,\n",
       "   18004,\n",
       "   17769,\n",
       "   12933,\n",
       "   18035,\n",
       "   17040,\n",
       "   18029,\n",
       "   14407],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18003,\n",
       "   16774,\n",
       "   16226,\n",
       "   17991,\n",
       "   18030,\n",
       "   910,\n",
       "   18035,\n",
       "   17613,\n",
       "   18001],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   17963,\n",
       "   16410,\n",
       "   910,\n",
       "   18035,\n",
       "   16226,\n",
       "   17985,\n",
       "   18031,\n",
       "   18035,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17227,\n",
       "   17816,\n",
       "   17582,\n",
       "   17933,\n",
       "   12751,\n",
       "   18035,\n",
       "   17582,\n",
       "   16226,\n",
       "   17975,\n",
       "   17404,\n",
       "   14407,\n",
       "   18035,\n",
       "   12229,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15892,\n",
       "   18035,\n",
       "   18035,\n",
       "   17888,\n",
       "   16077,\n",
       "   16226,\n",
       "   16941,\n",
       "   18035,\n",
       "   18024,\n",
       "   18012,\n",
       "   17780,\n",
       "   17905,\n",
       "   16816,\n",
       "   17952,\n",
       "   18035,\n",
       "   18035,\n",
       "   12873,\n",
       "   16077,\n",
       "   16226,\n",
       "   18026,\n",
       "   18035,\n",
       "   17522,\n",
       "   17911,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   15892],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17871,\n",
       "   18035,\n",
       "   18035,\n",
       "   14517,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   18027,\n",
       "   11692,\n",
       "   17925,\n",
       "   15185,\n",
       "   18025,\n",
       "   17925,\n",
       "   12933,\n",
       "   17911,\n",
       "   18035,\n",
       "   18035,\n",
       "   17079,\n",
       "   18024,\n",
       "   14407,\n",
       "   18035,\n",
       "   11692,\n",
       "   17427,\n",
       "   17957,\n",
       "   17734,\n",
       "   16226,\n",
       "   18032,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   18027,\n",
       "   12229,\n",
       "   18035,\n",
       "   17522,\n",
       "   18035,\n",
       "   12229,\n",
       "   18035,\n",
       "   18035,\n",
       "   15438,\n",
       "   18035,\n",
       "   12229,\n",
       "   910,\n",
       "   910,\n",
       "   910,\n",
       "   16310,\n",
       "   18000,\n",
       "   18035],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   17675,\n",
       "   14407,\n",
       "   18035,\n",
       "   14407,\n",
       "   17990,\n",
       "   12229,\n",
       "   17462,\n",
       "   18007,\n",
       "   17396,\n",
       "   12229,\n",
       "   18035,\n",
       "   14517,\n",
       "   18028,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18032,\n",
       "   18029,\n",
       "   18035,\n",
       "   16407,\n",
       "   17171,\n",
       "   16089,\n",
       "   17992,\n",
       "   18017,\n",
       "   18035,\n",
       "   910,\n",
       "   910,\n",
       "   910,\n",
       "   17734,\n",
       "   18019,\n",
       "   18017,\n",
       "   910,\n",
       "   910,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   11692,\n",
       "   17646,\n",
       "   18021,\n",
       "   17914,\n",
       "   18035,\n",
       "   17986,\n",
       "   14517,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   17968,\n",
       "   17109,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   15130,\n",
       "   18017,\n",
       "   18032,\n",
       "   16407,\n",
       "   18019,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   15185,\n",
       "   12751,\n",
       "   18035,\n",
       "   12751,\n",
       "   18032,\n",
       "   18035,\n",
       "   15130,\n",
       "   17556,\n",
       "   16941,\n",
       "   18021,\n",
       "   17826,\n",
       "   18023,\n",
       "   14407],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18028,\n",
       "   15185,\n",
       "   17984,\n",
       "   18001,\n",
       "   17522,\n",
       "   18035,\n",
       "   17339,\n",
       "   11692,\n",
       "   18013,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   16941,\n",
       "   18030,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   16310,\n",
       "   18035,\n",
       "   18016,\n",
       "   18035,\n",
       "   12873,\n",
       "   18035,\n",
       "   17835,\n",
       "   17998,\n",
       "   18035,\n",
       "   12229,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17582,\n",
       "   17969,\n",
       "   17961,\n",
       "   11692,\n",
       "   17732,\n",
       "   17859,\n",
       "   17711,\n",
       "   18029,\n",
       "   18035,\n",
       "   17885,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   16957,\n",
       "   16774,\n",
       "   17981,\n",
       "   16674,\n",
       "   17956,\n",
       "   910,\n",
       "   17556,\n",
       "   18035,\n",
       "   17744,\n",
       "   18035,\n",
       "   18035,\n",
       "   16407,\n",
       "   12873,\n",
       "   18026,\n",
       "   17645,\n",
       "   18035],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   16816,\n",
       "   18035,\n",
       "   18035,\n",
       "   17509,\n",
       "   11692,\n",
       "   18019,\n",
       "   18035,\n",
       "   910,\n",
       "   18008,\n",
       "   16077,\n",
       "   17911,\n",
       "   17645,\n",
       "   18035,\n",
       "   17617,\n",
       "   18035,\n",
       "   18035,\n",
       "   17772,\n",
       "   17945,\n",
       "   17957,\n",
       "   17944,\n",
       "   910],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18035,\n",
       "   18035,\n",
       "   11692,\n",
       "   17996,\n",
       "   0,\n",
       "   17588,\n",
       "   17905,\n",
       "   11692,\n",
       "   18027,\n",
       "   18029,\n",
       "   17891,\n",
       "   18035,\n",
       "   18035,\n",
       "   17932,\n",
       "   17888,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   16226,\n",
       "   17859,\n",
       "   18013,\n",
       "   0,\n",
       "   12751,\n",
       "   17998,\n",
       "   17775,\n",
       "   12873,\n",
       "   17933,\n",
       "   16774,\n",
       "   17783,\n",
       "   12933,\n",
       "   18025,\n",
       "   18006],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   18032,\n",
       "   17806,\n",
       "   18021,\n",
       "   18014,\n",
       "   14407,\n",
       "   910,\n",
       "   18035,\n",
       "   17928,\n",
       "   17984,\n",
       "   18035,\n",
       "   12873,\n",
       "   18035,\n",
       "   17920,\n",
       "   18019,\n",
       "   18035,\n",
       "   16816,\n",
       "   18035,\n",
       "   17798,\n",
       "   18017,\n",
       "   17798,\n",
       "   17972,\n",
       "   18035,\n",
       "   18013,\n",
       "   18035],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   18035,\n",
       "   12751,\n",
       "   17797,\n",
       "   17109,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   17404,\n",
       "   16957,\n",
       "   18020,\n",
       "   18011,\n",
       "   18012,\n",
       "   12229,\n",
       "   18035,\n",
       "   18015]],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_generator():\n",
    "    max_frequency = max(map.values())\n",
    "    \n",
    "    #train_cnt = 500\n",
    "    #cnxn = pyodbc.connect(cnstr_positive)\n",
    "    #query = \"SELECT count(*) as cnt FROM [dbo].[mixedmessages]\"\n",
    "    #cursor = cnxn.cursor()\n",
    "    #cursor.execute(query)\n",
    "    #for row in cursor:\n",
    "    #    train_cnt = row.cnt/2\n",
    "    #pyodbc.Connection.close(cnxn)\n",
    "    \n",
    "    x_test, y_test = ([] for i in range(2))\n",
    "    \n",
    "    query = \"SELECT top 100 [ttext], [ttype] FROM [dbo].[test]\"\n",
    "    while 1:\n",
    "        mdg = data_generator(cnstr_positive, query)\n",
    "\n",
    "        for current_set in mdg:\n",
    "            for sentence in current_set[0]:\n",
    "                words = tokenize(sentence)\n",
    "                w = []\n",
    "                #print(words)\n",
    "                for word in words:\n",
    "                    #print(word, map.get(word,0))\n",
    "                    w.append(max_frequency-map.get(word,0))\n",
    "                x_test.append(w)\n",
    "\n",
    "            for value in current_set[1]:\n",
    "                y_test.append(value)\n",
    "\n",
    "            if len(x_train) == batch_size:\n",
    "                #x_test = np.array(x_test)\n",
    "                #y_test = np.array(y_test)\n",
    "                x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "                x_test = x_test.tolist()\n",
    "                yield x_test, y_test    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dg = test_data_generator()\n",
    "next(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "#model.fit(x_train, y_train,\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=15,\n",
    "#          validation_data=(x_test, y_test))\n",
    "train_dg = train_data_generator()\n",
    "test_dg = test_data_generator()\n",
    "model.fit_generator(train_dg,steps_per_epoch = 1, epochs=1, validation_data=test_dg, validation_steps=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_example = np.array([[23, 75, 43, 225, 322]])\n",
    "my_example = sequence.pad_sequences(my_example, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_classes(my_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(my_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pymorphy2\n",
    "#morph = pymorphy2.MorphAnalyzer()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
