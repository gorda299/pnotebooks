{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to database\n",
    "\n",
    "Creating connection to Microsoft SQL Server and two databases with positive and negative sets. We should use generators for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positive_data_generator():\n",
    "    cnxn = pyodbc.connect('Trusted_Connection=yes;DRIVER={SQL Server};SERVER=DESKTOP-1RHDOBR\\GORDASQL;DATABASE=positive;UID=pyuser;PWD=pypypy')\n",
    "    cursor = cnxn.cursor()\n",
    "    cursor.execute(\"SELECT [id], [ttext], 1 as label FROM [dbo].[sortpos]\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in cursor:\n",
    "        r_id = row.id\n",
    "        r_text = row.ttext\n",
    "        X.append(r_id)\n",
    "        y.append(r_text)\n",
    "        \n",
    "        if len(X) == batch_size:\n",
    "            npx = np.array(X)\n",
    "            npy = np.array(y)\n",
    "            yield npx, npy\n",
    "            X, y = [], []\n",
    "    pyodbc.Connection.close(cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_data_generator():\n",
    "    cnxn = pyodbc.connect('Trusted_Connection=yes;DRIVER={SQL Server};SERVER=DESKTOP-1RHDOBR\\GORDASQL;DATABASE=negative;UID=pyuser;PWD=pypypy')\n",
    "    cursor = cnxn.cursor()\n",
    "    cursor.execute(\"SELECT [id], [ttext], 0 as label FROM [dbo].[sortneg]\")\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in cursor:\n",
    "        r_id = row.id\n",
    "        r_text = row.ttext\n",
    "        X.append(r_id)\n",
    "        y.append(r_text)\n",
    "        \n",
    "        if len(X) == batch_size:\n",
    "            npx = np.array(X)\n",
    "            npy = np.array(y)\n",
    "            yield npx, npy\n",
    "            X, y = [], []\n",
    "    pyodbc.Connection.close(cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "We should encode words as their indexes (computed by overall frequency in the dataset).\n",
    "Using russian http://www.ruscorpora.ru/en/\n",
    "#### Step 1. Clear dataset. \n",
    "#### Step 2. Select meaningful words.\n",
    "#### Step 3. Calculate frequency of each word\n",
    "#### Step 4. Replace words by indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import ieer #averaged_perceptron_tagger_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordListCorpusReader' object has no attribute 'demo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-e672c71486bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WordListCorpusReader' object has no attribute 'demo'"
     ]
    }
   ],
   "source": [
    "stopwords.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(file_text):\n",
    "    #firstly let's apply nltk tokenization\n",
    "    tokens = nltk.word_tokenize(file_text)\n",
    "\n",
    "    #let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if ( i not in string.punctuation )]\n",
    "\n",
    "    #deleting stop_words\n",
    "    stop_words = stopwords.words('russian')\n",
    "    stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на'])\n",
    "    tokens = [i for i in tokens if ( i not in stop_words )]\n",
    "\n",
    "    #cleaning words\n",
    "    tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdg = positive_data_generator()\n",
    "ndg = negative_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([410279586921189376, 410279593686626305, 410279648573276160,\n",
       "        410279709126430720, 410279710841925632, 410279711085199360,\n",
       "        410279750129549312, 410279750352244736, 410279753468633088,\n",
       "        410279802676203520], dtype=int64),\n",
       " array(['@NatahaSergeevna , дурочка ты Наташка ;) во сколько у тебя пробник ?:*',\n",
       "        'RT @zijelesij: 2061564/2 ну.. можно наверное найти на яндекс.музыка)',\n",
       "        'Дурачиться утром, делая хорошим настроение друг другу, потрясающе :*',\n",
       "        'RT @szhurova: Как автобус съел пассажира :-))) http://t.co/pVfTIIyDi5',\n",
       "        'Что за прикол, уже второй день подряд?))добавляются свингеры) http://t.co/DVPcHHH006',\n",
       "        'Доброе утро.) как приятно вставать хотя бы на два часа позже.)',\n",
       "        '@Rudakov_i_a @MP_Blago63 @Filaretov_IA А аккаунт в твиттере?)',\n",
       "        'С Днём Рождения любимая Айза!!! Ты само совершенство, всегда для меня была самой лучшей!! Я горжусь табой:*** http://t.co/Es1tZ3Fogm',\n",
       "        'Оказывается, мой заварочный чайник умеет мурлыкать. Когда моешь его губкой :-)',\n",
       "        'Это пипец,товарищи)чувствую себя плачущим снеговиком с потекшей тушью)Я в шоке!'],\n",
       "       dtype='<U132'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(pdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([408911426514739200, 408911550079336448, 408911823769853952,\n",
       "        408911903877255168, 408911904736694272, 408911953826828288,\n",
       "        408912064770736128, 408912288930725888, 408912603533303808,\n",
       "        408912605055832064], dtype=int64),\n",
       " array(['идиотский твиттер!! как же ты глючишь.. ;(',\n",
       "        'RT @procrastelina: RT если ниже ростом даже чем губин((((',\n",
       "        '@kakos1904 Бедный мой, ты же в школе. Твоя физика закончится раньше чем я до тебя доеду :( Я б забрал',\n",
       "        'Спасибо тем кто меня в данный момент поддерживает с моей проблемой,спасибо правда,спасибо тебе ни кто(',\n",
       "        'а если макарошки отварить и запечь с луком,морковкой,майонезом,чесноком и всякими приправками,будет ОМНОМНОМ! *О* сыра нет,жаль(',\n",
       "        'завтра по химии диктант, нужно хорошо подготовиться(',\n",
       "        'Сейчас бы в кроватку, спать ( а ещё дофигища дел не сделано -_-',\n",
       "        '@No_Name_Okay_ мне обязательно!(\\\\nв 19:30 начинается..\\\\nМожет пойдём сейчас и потом ты меня проводишь?',\n",
       "        'мария ра самые убогие магазины, в который раз убеждаюсь. Еще 2 часа работы(',\n",
       "        'Зря торопился, все равно прийдется в выходные работать :('],\n",
       "       dtype='<U128'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ndg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
